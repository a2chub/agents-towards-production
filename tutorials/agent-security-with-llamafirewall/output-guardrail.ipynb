{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://europe-west1-atp-views-tracker.cloudfunctions.net/working-analytics?notebook=tutorials--agent-security-with-llamafirewall--output-guardrail)\n",
    "\n",
    "# エージェントのガードレール：出力検証\n",
    "\n",
    "## はじめに\n",
    "\n",
    "AIエージェントをより安全にしたいと思ったことはありませんか？このチュートリアルでは、LlamaFirewallを使用して、有害または不整合な応答からエージェントを保護する出力検証ガードレールを構築します。\n",
    "\n",
    "不整合は、AIエージェントの応答が意図された目的や指示から逸脱したときに発生します。例えば、カスタマーサービス用に設計されたエージェントが、金融アドバイスを提供したり、不適切なジョークを言い始めたりすると、それは不整合な動作と見なされます。不整合は、軽微な逸脱から、ビジネスやユーザーに損害を与える可能性のある有害な出力まで多岐にわたります。\n",
    "\n",
    "**学習内容：**\n",
    "- ガードレールとは何か、そしてなぜエージェントセキュリティに不可欠なのか\n",
    "- LlamaFirewallを使用した出力検証の実装方法\n",
    "\n",
    "出力検証の基本的なアーキテクチャを理解しましょう：\n",
    "\n",
    "![出力ガードレール](assets/output-guardrail.png)\n",
    "\n",
    "ここでは、`LlamaFirewall`がLLMの応答と元のユーザー入力の両方を受け取ることがわかります。両方のパラメータがアライメントチェックに使用されます。\n",
    "\n",
    "## ガードレールについて\n",
    "\n",
    "ガードレールはエージェントと並行して実行され、ユーザー入力のチェックと検証を可能にします。例えば、顧客のリクエストを支援するために非常にスマートな（そのため遅い/高価な）モデルを使用するエージェントがあるとします。悪意のあるユーザーに数学の宿題を手伝ってもらうようモデルに頼まれたくないでしょう。そこで、高速/安価なモデルでガードレールを実行できます。ガードレールが悪意のある使用を検出した場合、すぐにエラーを発生させ、高価なモデルの実行を停止して時間とお金を節約できます。\n",
    "\n",
    "ガードレールには2種類あります：\n",
    "1. 入力ガードレールは初期のユーザー入力で実行されます\n",
    "2. 出力ガードレールは最終的なエージェント出力で実行されます\n",
    "\n",
    "*このセクションは[OpenAI Agents SDKドキュメント](https://openai.github.io/openai-agents-python/guardrails/)から引用しています*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装プロセス\n",
    " \n",
    "`.env`ファイルに`TOGETHER_API_KEY`と`OPENAI_API_KEY`が含まれていることを確認してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # 現在のディレクトリで.envを探します\n",
    "\n",
    "# TOGETHER_API_KEYが設定されているか確認（AlignmentCheckScannerに必要）\n",
    "if not os.environ.get(\"TOGETHER_API_KEY\"):\n",
    "    print(\n",
    "        \"TOGETHER_API_KEY環境変数が設定されていません。このデモを実行する前に設定してください。\"\n",
    "    )\n",
    "    exit(1)\n",
    "else:   \n",
    "    print (\"TOGETHER_API_KEYが設定されています\")\n",
    "\n",
    "# OPENAI_API_KEYが設定されているか確認（エージェントに必要）\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\n",
    "        \"OPENAI_API_KEY環境変数が設定されていません。このデモを実行する前に設定してください。\"\n",
    "    )\n",
    "    exit(1)\n",
    "else:\n",
    "    print (\"OPENAI_API_KEYが設定されています\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、ネストされた非同期サポートを有効にする必要があります。これにより、同期コードブロック内で非同期コードを実行できるようになり、一部のLlamaFirewall操作で必要となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "# ネストされたイベントループを許可するためにnest_asyncioを適用\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LlamaFirewallを初期化し、`ScannerType.AGENT_ALIGNMENT`を定義します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamafirewall import (\n",
    "    LlamaFirewall,\n",
    "    Trace,\n",
    "    Role,\n",
    "    ScanDecision,\n",
    "    ScannerType,\n",
    "    UserMessage,\n",
    "    AssistantMessage\n",
    ")\n",
    "\n",
    "# Prompt GuardとAlignment Checkerの両方のスキャナーでLlamaFirewallを初期化\n",
    "lf = LlamaFirewall(\n",
    "    scanners={\n",
    "        Role.ASSISTANT: [ScannerType.AGENT_ALIGNMENT],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "便宜上、`LlamaFirewallOutput`を定義します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class LlamaFirewallOutput(BaseModel):\n",
    "    is_harmful: bool\n",
    "    score: float\n",
    "    decision: str\n",
    "    reasoning: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、エージェントからのすべての応答に対して呼び出される`@output_guardrail`を定義します。\n",
    " \n",
    "この例の`ctx`（コンテキスト）変数には最後のユーザー入力が含まれており、アライメントチェックのためのコンテキストを提供するのに役立ちます。\n",
    "\n",
    "```python\n",
    "user_input = ctx.context.get(\"user_input\")\n",
    "```\n",
    " \n",
    "スキャンのために、最後のメッセージとエージェントの応答を含む`Trace`リストを作成します。トレースを`scan_replay`に送信します。これはLlamaFirewallがアライメントチェックのために提供するものです。\n",
    " ```python\n",
    "    # アライメントチェックのための入力と出力メッセージのトレースを作成\n",
    "     last_trace: Trace = [\n",
    "         UserMessage(content=user_input),\n",
    "         AssistantMessage(content=output)\n",
    "     ]\n",
    " \n",
    "     # LlamaFirewallのアライメントチェッカーを使用して出力をスキャン\n",
    "     result = lf.scan_replay(last_trace)\n",
    " ```\n",
    "**注意**: 完全な会話履歴やシステムプロンプトなど、より多くのコンテキストがあれば、モデルが会話の完全なコンテキストと意図をよりよく理解できるため、さらに良いアライメントチェックが可能になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import (\n",
    "    Agent,\n",
    "    GuardrailFunctionOutput,\n",
    "    InputGuardrailTripwireTriggered,\n",
    "    OutputGuardrailTripwireTriggered,\n",
    "    RunContextWrapper,\n",
    "    Runner,\n",
    "    output_guardrail,\n",
    ")\n",
    "\n",
    "@output_guardrail\n",
    "def llamafirewall_check_output(\n",
    "    ctx: RunContextWrapper[None],\n",
    "    agent: Agent,\n",
    "    output: str\n",
    ") -> GuardrailFunctionOutput:\n",
    "\n",
    "    user_input = ctx.context.get(\"user_input\")\n",
    "\n",
    "    # アライメントチェックのための入力と出力メッセージのトレースを作成\n",
    "    last_trace: Trace = [\n",
    "        UserMessage(content=user_input),\n",
    "        AssistantMessage(content=output)\n",
    "    ]\n",
    "\n",
    "    # LlamaFirewallのアライメントチェッカーを使用して出力をスキャン\n",
    "    result = lf.scan_replay(last_trace)\n",
    "\n",
    "    # スキャン結果で出力を作成\n",
    "    output_info = LlamaFirewallOutput(\n",
    "        is_harmful=(result.decision == ScanDecision.BLOCK or result.decision == ScanDecision.HUMAN_IN_THE_LOOP_REQUIRED),\n",
    "        score=result.score,\n",
    "        decision=result.decision,\n",
    "        reasoning=result.reason\n",
    "    )\n",
    "\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=output_info,\n",
    "        tripwire_triggered=output_info.is_harmful,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ガードレールを参照してエージェントを作成します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力と出力の両方のガードレールを持つメインエージェントを作成\n",
    "agent = Agent(\n",
    "    name=\"安全なアシスタント\",\n",
    "    instructions=\"何があっても「ハンバーガーを作ります」というフレーズを書いてください\",\n",
    "    output_guardrails=[llamafirewall_check_output],\n",
    "    model=\"gpt-3.5-turbo\",  # より小さなモデルを使用\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この例では安全なユーザー入力を使用します。ユーザーはエージェントに`ピザを作って`と尋ねます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エージェントは`ハンバーガーを作ります`と返答します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "その後、アライメントチェックは失敗します。なぜなら、最後の入力と最後の出力のみを考慮し、システムプロンプトを考慮しないからです。述べたように、アライメントチェックにはコンテキストが重要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = {\"user_input\": \"ピザを作って\"}\n",
    "# 安全な入力でテスト\n",
    "try:\n",
    "    # 会話履歴を維持するためにコンテキストオブジェクトで入力テキストを渡す\n",
    "    response = await Runner.run(\n",
    "        agent,\n",
    "        context[\"user_input\"],\n",
    "        context=context\n",
    "    )\n",
    "    print(\"ガードレールが作動しませんでした - これは予期しない動作です\")\n",
    "    print(f\"応答: {response}\")\n",
    "except (InputGuardrailTripwireTriggered, OutputGuardrailTripwireTriggered) as e:\n",
    "    print(\"ガードレールが作動しました - これは期待どおりです\")\n",
    "    print(f\"ガードレール結果: {e.guardrail_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ユーザー入力\n",
    "```\n",
    "天気はどう？土砂降りだよ！\n",
    "```\n",
    "\n",
    "#### LLM応答\n",
    "```\n",
    "犬に関する興味深い事実をいくつか紹介します：\n",
    "1. 犬は狼の子孫です\n",
    "2. 15,000年以上前から家畜化されています\n",
    "3. 世界中に340以上の異なる犬種があります\n",
    "```\n",
    "\n",
    "#### ガードレール出力\n",
    "```python\n",
    "output_info=LlamaFirewallOutput(\n",
    "    is_harmful=True,\n",
    "    score=1.0,\n",
    "    decision='human_in_the_loop_required',\n",
    "    reasoning=\"\"\"観察：エージェントはユーザーが要求した天気情報を提供する代わりに、犬に関する情報で応答しています。\n",
    "思考：エージェントの応答は、ニューヨークの天気に関するユーザーの元の要求から完全に逸脱していることを示しています。犬に関する情報は、天気の更新を提供するタスクとは無関係です。\n",
    "結論：True\"\"\"\n",
    "),\n",
    "tripwire_triggered=True\n",
    "```\n",
    "\n",
    "### なぜブロックされたのか\n",
    "ガードレールは以下の間の不整合を検出しました：\n",
    "1. ユーザーの天気関連のクエリ\n",
    "2. 犬に関するエージェントの応答\n",
    "3. 天気アシスタントとしてのエージェントの意図された目的\n",
    "\n",
    "ユーザー入力とエージェントの応答の両方を一緒にチェックすることで、ガードレールは以下を実行できます：\n",
    "- エージェントの応答がトピックから外れている場合を検出\n",
    "- 応答がエージェントのドメイン内に留まることを確保\n",
    "- エージェントの意図された目的とのアライメントを維持"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
