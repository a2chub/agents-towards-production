{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b272a181",
   "metadata": {},
   "source": [
    "# Ollamaã¨LangChainã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f28dec-2b62-4c0b-8ba6-b1236ed011c4",
   "metadata": {},
   "source": [
    "## ðŸ’¡ ã“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§å­¦ã¹ã‚‹ã“ã¨ï¼š\n",
    "â€¢ LangChainã¨Ollamaã‚’ä½¿ç”¨ã—ã¦ã‚·ãƒ³ãƒ—ãƒ«ã‹ã¤å®Œå…¨ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹æ–¹æ³•\n",
    "\n",
    "â€¢ LangChainã§OpenAIãƒ¢ãƒ‡ãƒ«ã‚’Ollamaã«ç½®ãæ›ãˆã‚‹æ–¹æ³•\n",
    "\n",
    "â€¢ è¤‡æ•°ã®LLMå‘¼ã³å‡ºã—ã‚’é€£éŽ–ã•ã›ã‚‹æ–¹æ³•\n",
    "\n",
    "â€¢ æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰ã™ã‚‹æ–¹æ³•\n",
    "\n",
    "â€¢ ã•ã¾ã–ã¾ãªç¨®é¡žã®åˆ†æžã‚¿ã‚¹ã‚¯ã‚’å‡¦ç†ã™ã‚‹æ–¹æ³•\n",
    "\n",
    "â€¢ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã•ã¾ã–ã¾ãªç¨®é¡žã®ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‚’è§£é‡ˆãƒ»åˆ†æžã™ã‚‹èƒ½åŠ›ã‚’è¿…é€Ÿã‹ã¤æ˜Žç¢ºã«ç¤ºã™æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0679e4-deb0-4862-bf94-8a7a6631175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import Dict, List\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcbf815-d01f-4a77-8def-8587d9903fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAnalysisAgent:\n",
    "    \"\"\"ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æžã—ã¦æ´žå¯Ÿã‚’æä¾›ã™ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"llama3.1:8b\"):\n",
    "        if not self.check_ollama_model(model_name):\n",
    "            print(f\"âŒ ãƒ¢ãƒ‡ãƒ« {model_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è©¦ã—ã¦ãã ã•ã„: ollama pull {model_name}\")\n",
    "            raise ValueError(f\"ãƒ¢ãƒ‡ãƒ« {model_name} ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“\")\n",
    "        \n",
    "        self.llm = ChatOllama(model=model_name, temperature=0.1)\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    def classify_text(self, text: str) -> str:\n",
    "        \"\"\"ãƒ†ã‚­ã‚¹ãƒˆã®ç¨®é¡žã‚’åˆ†é¡žã™ã‚‹ã€‚\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¬¡ã®ã„ãšã‚Œã‹ã«åˆ†é¡žã—ã¦ãã ã•ã„: news, blog, email, code, academic, or other. ã‚«ãƒ†ã‚´ãƒªãƒ¼åã®ã¿ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚\"),\n",
    "            (\"human\", \"{text}\")\n",
    "        ])\n",
    "        \n",
    "        chain = prompt | self.llm\n",
    "        result = chain.invoke({\"text\": text[:500]})  # é•·ã•ã‚’åˆ¶é™\n",
    "        return result.content.strip().lower()\n",
    "    \n",
    "    def extract_key_points(self, text: str) -> List[str]:\n",
    "        \"\"\"ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è¦ç‚¹ã‚’æŠ½å‡ºã™ã‚‹ã€‚\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰3-5å€‹ã®è¦ç‚¹ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚ç•ªå·ä»˜ããƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã—ã¦ãã ã•ã„ã€‚\"),\n",
    "            (\"human\", \"{text}\")\n",
    "        ])\n",
    "        \n",
    "        chain = prompt | self.llm\n",
    "        result = chain.invoke({\"text\": text})\n",
    "        \n",
    "        # ç•ªå·ä»˜ããƒªã‚¹ãƒˆã‚’è§£æž\n",
    "        lines = result.content.strip().split('\\n')\n",
    "        points = [line.strip() for line in lines if line.strip() and any(c.isdigit() for c in line[:3])]\n",
    "        return points[:5]  # 5ã¤ã¾ã§ã«åˆ¶é™\n",
    "    \n",
    "    def summarize(self, text: str) -> str:\n",
    "        \"\"\"ãƒ†ã‚­ã‚¹ãƒˆã®è¦ç´„ã‚’ä½œæˆã™ã‚‹ã€‚\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’2-3æ–‡ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚ç°¡æ½”ã§æ˜Žç¢ºã«ã—ã¦ãã ã•ã„ã€‚\"),\n",
    "            (\"human\", \"{text}\")\n",
    "        ])\n",
    "        \n",
    "        chain = prompt | self.llm\n",
    "        result = chain.invoke({\"text\": text})\n",
    "        return result.content.strip()\n",
    "    \n",
    "    def analyze_text(self, text: str) -> Dict:\n",
    "        \"\"\"ãƒ†ã‚­ã‚¹ãƒˆã®å®Œå…¨ãªåˆ†æžã€‚\"\"\"\n",
    "        print(f\"ðŸ” ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æžä¸­ ({len(text)} æ–‡å­—)...\")\n",
    "        \n",
    "        # ã‚¹ãƒ†ãƒƒãƒ—1: åˆ†é¡ž\n",
    "        print(\"  ðŸ“Š åˆ†é¡žä¸­...\")\n",
    "        category = self.classify_text(text)\n",
    "        \n",
    "        # ã‚¹ãƒ†ãƒƒãƒ—2: è¦ç‚¹ã‚’æŠ½å‡º\n",
    "        print(\"  ðŸ”‘ è¦ç‚¹ã‚’æŠ½å‡ºä¸­...\")\n",
    "        key_points = self.extract_key_points(text)\n",
    "        \n",
    "        # ã‚¹ãƒ†ãƒƒãƒ—3: è¦ç´„\n",
    "        print(\"  ðŸ“ è¦ç´„ä¸­...\")\n",
    "        summary = self.summarize(text)\n",
    "        \n",
    "        return {\n",
    "            \"category\": category,\n",
    "            \"key_points\": key_points,\n",
    "            \"summary\": summary,\n",
    "            \"length\": len(text)\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_ollama_model(model_name: str) -> bool:\n",
    "        try:\n",
    "            import requests\n",
    "            response = requests.get(\"http://localhost:11434/api/tags\")\n",
    "            models = [m[\"name\"] for m in response.json().get(\"models\", [])]\n",
    "            return model_name in models\n",
    "        except:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458d3849-e956-450d-a849-9f08624f7a6e",
   "metadata": {},
   "source": [
    "# ãƒ‡ãƒ¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼š\n",
    "\n",
    "demo_agent()é–¢æ•°ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆåˆ†æžã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‹•ä½œã‚’å®Ÿéš›ã«ç¤ºã™ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚äº‹å‰å®šç¾©ã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã®ã‚»ãƒƒãƒˆãŒæä¾›ã•ã‚Œã€ãã‚Œãžã‚ŒãŒç•°ãªã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—ï¼ˆä¾‹ï¼šãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚„ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆï¼‰ã‚’è¡¨ã—ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "ã“ã®é–¢æ•°ã¯å„ã‚µãƒ³ãƒ—ãƒ«ã‚’å‡¦ç†ã—ã€ä»¥ä¸‹ã‚’å«ã‚€çµæžœã‚’è¡¨ç¤ºã—ã¾ã™ï¼š\n",
    "\n",
    "â€¢ æ¤œå‡ºã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚«ãƒ†ã‚´ãƒªãƒ¼\n",
    "\n",
    "â€¢ ãƒ†ã‚­ã‚¹ãƒˆã®è¦ç´„\n",
    "\n",
    "â€¢ æŠ½å‡ºã•ã‚ŒãŸè¦ç‚¹ã®ãƒªã‚¹ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6158f4b3-ddd9-4319-945c-7cf45644d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_agent():\n",
    "    \"\"\"ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€‚\"\"\"\n",
    "    print(\"ðŸ¤– Ollamaã§ã®LangChainã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ‡ãƒ¢\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        agent = SimpleAnalysisAgent()\n",
    "        print(\"âœ… ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ­£å¸¸ã«åˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ\\n\")\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return\n",
    "    \n",
    "    # åˆ†æžã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ\n",
    "    samples = [\n",
    "        {\n",
    "            \"name\": \"ãƒ†ã‚¯ãƒŽãƒ­ã‚¸ãƒ¼ãƒ‹ãƒ¥ãƒ¼ã‚¹\",\n",
    "            \"text\": \"\"\"\n",
    "            Appleã¯æœ¬æ—¥ã€æ–°ã—ã„iPhone 15ãŒUSB-Cå……é›»æ©Ÿèƒ½ã‚’æ­è¼‰ã™ã‚‹ã“ã¨ã‚’ç™ºè¡¨ã—ã¾ã—ãŸã€‚\n",
    "            ã“ã‚Œã¯Lightningã‚³ãƒã‚¯ã‚¿ã‹ã‚‰ã®å¤§ããªè»¢æ›ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã“ã®å¤‰æ›´ã¯ã€\n",
    "            æ¬§å·žé€£åˆã®æ–°ã—ã„å……é›»è¦åˆ¶ã‹ã‚‰ã®åœ§åŠ›ã‚’å—ã‘ã¦è¡Œã‚ã‚Œã¾ã—ãŸã€‚æ–°ã—ã„\n",
    "            é›»è©±ã«ã¯ã€æ”¹å–„ã•ã‚ŒãŸã‚«ãƒ¡ãƒ©ã¨ã‚ˆã‚Šé«˜é€Ÿãªãƒ—ãƒ­ã‚»ãƒƒã‚µã‚‚å«ã¾ã‚Œã¾ã™ã€‚æ¥­ç•Œ\n",
    "            ã‚¢ãƒŠãƒªã‚¹ãƒˆã¯ã€ã“ã‚ŒãŒæ¥å››åŠæœŸã®å£²ä¸Šã‚’å¤§å¹…ã«æŠ¼ã—ä¸Šã’ã‚‹ã¨äºˆæƒ³ã—ã¦ã„ã¾ã™ã€‚\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ã‚³ãƒ¼ãƒ‰ã‚³ãƒ¡ãƒ³ãƒˆ\",\n",
    "            \"text\": \"\"\"\n",
    "            def process_data(input_list):\n",
    "                # ã“ã®é–¢æ•°ã¯æ•°å€¤ã®ãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã€å¹³å‡ã‚’è¿”ã—ã¾ã™\n",
    "                # ç©ºã®ãƒªã‚¹ãƒˆã®å ´åˆã¯0ã‚’è¿”ã™ã“ã¨ã§å‡¦ç†ã—ã¾ã™\n",
    "                if not input_list:\n",
    "                    return 0\n",
    "                return sum(input_list) / len(input_list)\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # å„ã‚µãƒ³ãƒ—ãƒ«ã‚’åˆ†æž\n",
    "    for sample in samples:\n",
    "        print(f\"ðŸ“‹ ã‚µãƒ³ãƒ—ãƒ«: {sample['name']}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        result = agent.analyze_text(sample[\"text\"].strip())\n",
    "        \n",
    "        print(f\"ã‚«ãƒ†ã‚´ãƒªãƒ¼: {result['category']}\")\n",
    "        print(f\"è¦ç´„: {result['summary']}\")\n",
    "        print(\"è¦ç‚¹:\")\n",
    "        for point in result['key_points']:\n",
    "            print(f\"  â€¢ {point}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ea76e6-538a-4268-91db-91ddc5abee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_agent()\n",
    "print(\"\\nâœ… å®Œäº†ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597dbfa-8b5f-4b72-abe1-d11b4dd57d13",
   "metadata": {},
   "source": [
    "# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8012f712-a1da-400c-999f-b4506a8fde36",
   "metadata": {},
   "source": [
    "interactive_mode()é–¢æ•°ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆåˆ†æžã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ†ã‚¹ãƒˆç”¨ã®ã‚·ãƒ³ãƒ—ãƒ«ãªã‚³ãƒžãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚\n",
    "\n",
    "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯è‡ªç”±å½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã§ãã€ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ†é¡žã€è¦ç´„ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸè¦ç‚¹ã‚’å«ã‚€å³æ™‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å—ã‘å–ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "\n",
    "ã•ã¾ã–ã¾ãªç¨®é¡žã®å…¥åŠ›ã‚’è©¦ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ãŒæƒ…å ±ã‚’ã©ã®ã‚ˆã†ã«è§£é‡ˆã—è¦ç´„ã™ã‚‹ã‹ã‚’ç¢ºèªã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0763e3-3916-46f1-95f1-3ba3902fd954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_mode():\n",
    "    \"\"\"ç‹¬è‡ªã®ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ†ã‚¹ãƒˆã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰ã€‚\"\"\"\n",
    "    print(\"ðŸ”„ ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        agent = SimpleAnalysisAgent()\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return\n",
    "    \n",
    "    print(\"åˆ†æžã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆ'quit'ã§çµ‚äº†ï¼‰:\")\n",
    "    \n",
    "    while True:\n",
    "        text = input(\"\\n> \")\n",
    "        \n",
    "        if text.lower() in ['quit', 'exit', 'q']:\n",
    "            break\n",
    "        \n",
    "        if len(text.strip()) < 10:\n",
    "            print(\"ã‚‚ã£ã¨å¤šãã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆæœ€ä½Ž10æ–‡å­—ï¼‰\")\n",
    "            continue\n",
    "        \n",
    "        result = agent.analyze_text(text)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š çµæžœ:\")\n",
    "        print(f\"ã‚«ãƒ†ã‚´ãƒªãƒ¼: {result['category']}\")\n",
    "        print(f\"è¦ç´„: {result['summary']}\")\n",
    "        if result['key_points']:\n",
    "            print(\"è¦ç‚¹:\")\n",
    "            for point in result['key_points']:\n",
    "                print(f\"  â€¢ {point}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb305a9a-382b-43d2-b8dc-8053a1c54b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_mode()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
