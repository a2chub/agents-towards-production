{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98bbe059-f253-43b5-85cd-c8eb21311153",
   "metadata": {},
   "source": [
    "# Ollamaの基本的な使用例\n",
    "\n",
    "OpenAI/その他のAPI呼び出しをOllamaで置き換える最もシンプルな方法を示します。\n",
    "エージェントに進む前に、コアコンセプトを理解するのに最適です。\n",
    "\n",
    "1) 直接API呼び出し\n",
    "2) Ollama APIパラメータ\n",
    "3) 基本的なLangChain統合\n",
    "4) 会話"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26077269-865a-44ee-9c55-3a0614e36f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55c3f22-c272-4487-8c3b-58eff99231f5",
   "metadata": {},
   "source": [
    "# Ollamaが実行されているか確認しましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0e4d3-088a-45ef-8e6b-a86ca0dfd2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ollama_running():\n",
    "    \"\"\"Ollamaが利用可能かチェックする。\"\"\"\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "        return response.status_code == 200\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "if not check_ollama_running():\n",
    "    print(\"❌ Ollamaが実行されていません！\")\n",
    "    print(\"次のコマンドで起動してください: ollama serve\")\n",
    "    print(\"モデルがあることを確認してください: ollama pull llama3.1:8b\")\n",
    "else:\n",
    "    print(\"✅ Ollamaが実行されています\\n\")\n",
    "    print(\"🚀 Ollamaの基本的な使用例\")\n",
    "    print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8757427b-ab1b-42e5-8ab9-b91a17b92dce",
   "metadata": {},
   "source": [
    "# 直接API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20553578-d6e6-4bfd-8296-9374748bcb82",
   "metadata": {},
   "source": [
    "# systemとuserの呼び出し：\n",
    "✅ role: \"system\"\n",
    "目的：モデルの初期動作、トーン、または制約を設定します。\n",
    "使用例：会話が始まる前に、アシスタントの個性、スコープ、または指示を定義します。\n",
    "モデルは一度読み込み、以降のすべての応答を形成するために使用します。\n",
    "ほとんどのアプリケーションでは、ユーザーには表示されません。\n",
    "\n",
    "✅ role: \"user\"\n",
    "目的：ユーザーからの実際の質問や入力を表します。\n",
    "モデルに応答を促します。\n",
    "アシスタントメッセージが続くことで、対話のやり取りを継続できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b113ca-f385-45ce-87a4-7a289da45cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_1_direct_api(sys_promt, usr_promt):\n",
    "    # これはOpenAI API呼び出しを置き換えます\n",
    "    # response = requests.post(\"http://localhost:11434/api/chat\", json={\n",
    "    #     \"model\": \"llama3.1:8b\",\n",
    "    #     \"messages\": [\n",
    "    #         {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    #         {\"role\": \"user\", \"content\": \"What is Python?\"}\n",
    "    #     ]\n",
    "    # })\n",
    "    response = requests.post(\"http://localhost:11434/api/chat\", json={\n",
    "        \"model\": \"llama3.1:8b\",\n",
    "        \"messages\": [{\"role\": \"system\", \"content\": sys_promt},\n",
    "                     {\"role\": \"user\", \"content\":  usr_promt}\n",
    "                     ],\n",
    "        \"stream\": False  # ストリーミングでないことを確認\n",
    "    })\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(f\"応答: {result[\"message\"][\"content\"]}\")\n",
    "    else:\n",
    "        print(f\"エラー: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f43c78-270a-483d-a427-2a94f56b4868",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"例1: 直接API呼び出し\")\n",
    "print(\"-\" * 30)\n",
    "sys_promt = \"あなたは役立つアシスタントです。\"\n",
    "usr_promt = \"Pythonとは何ですか？\"\n",
    "example_1_direct_api(sys_promt,usr_promt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6658f7f-c8a7-4126-aabb-e6a98aac9cce",
   "metadata": {},
   "source": [
    "## Ollama APIパラメータ\n",
    "\n",
    "Ollamaは広範なカスタマイズオプションを提供します。最も一般的に使用されるパラメータは以下の通りです：\n",
    "\n",
    "| パラメータ | 型 | デフォルト | 説明 |\n",
    "|-----------|------|---------|-------------|\n",
    "| `model` | string | - | **必須。** モデル識別子（例：`\"llama3.1:8b\"`） |\n",
    "| `messages` | array | - | `/api/chat`用のチャット会話 |\n",
    "| `stream` | boolean | true | 生成されるにつれて応答をストリーム |\n",
    "| `temperature` | float | 0.8 | ランダム性（0.0 = 決定的、2.0 = 非常にランダム） |\n",
    "| `top_p` | float | 0.9 | 核サンプリング（0.1 = 上位10%のトークンのみ） |\n",
    "| `num_predict` | int | 128 | 生成する最大トークン数（-1 = 無制限） |\n",
    "| `repeat_penalty` | float | 1.1 | トークンの繰り返しに対するペナルティ |\n",
    "| `system` | string | - | 動作をガイドするシステムメッセージ |\n",
    "| `stop` | array | - | これらの文字列で生成を停止 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d50bb6-034d-4655-a9fc-3e02e87f3b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_2_with_parameters(temperature, num_predict, usr_promt):\n",
    "   \n",
    "    response = requests.post(\"http://localhost:11434/api/chat\", json={\n",
    "        \"model\": \"llama3.1:8b\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": usr_promt}],\n",
    "        \"temperature\": temperature,  # 創造性のための高い温度\n",
    "        \"num_predict\": num_predict,   # 応答の長さを制限\n",
    "        \"stream\": False  # ストリーミングでないことを確認\n",
    "    })\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()[\"message\"][\"content\"]\n",
    "        print(f\"創造的な応答: {result}\")\n",
    "    else:\n",
    "        print(f\"エラー: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeb0e36-2c2c-4792-8f9f-c3799a31d487",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n例2: パラメータ付き\")\n",
    "print(\"-\" * 30)\n",
    "usr_promt = \"ロボットについての創造的な物語を書いてください。\"\n",
    "temperature = 0.8\n",
    "num_predict = 100\n",
    "example_2_with_parameters(temperature, num_predict, usr_promt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25384d92-57f2-4486-9c21-93ac0befb814",
   "metadata": {},
   "source": [
    "# LangChain統合\n",
    "\n",
    "| 機能 | ChatOllama | 直接API |\n",
    "|---------|------------|------------|\n",
    "| `抽象化レベル` | 高 | 低 |\n",
    "| `使いやすさ` | より簡単 | 手動フォーマットが必要 |\n",
    "| `カスタマイズ（ヘッダーなど）` | 限定的 | 完全 |\n",
    "| `依存関係` | LangChainが必要 | requestsのみ | \n",
    "| `最適な用途` | RAGパイプライン、高速プロトタイピング | カスタムツール、低レベル制御 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784ee49-5953-4872-bf1d-6c3cbbb6b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_3_langchain_basic(usr_promt):    \n",
    "    try:\n",
    "        from langchain_community.chat_models import ChatOllama\n",
    "        \n",
    "        # ChatOpenAIをChatOllamaで置き換える\n",
    "        llm = ChatOllama(model=\"llama3.1:8b\", temperature=0.1)\n",
    "        \n",
    "        response = llm.invoke(usr_promt)\n",
    "        print(f\"LangChain応答: {response.content}\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"LangChainがインストールされていません。実行してください: pip install langchain langchain-community\")\n",
    "    except Exception as e:\n",
    "        print(f\"エラー: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b309023-124e-43c9-a7ab-86ca4fd001ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n例3: LangChain統合\")\n",
    "print(\"-\" * 30)\n",
    "usr_promt = \"機械学習を一文で説明してください。\"\n",
    "example_3_langchain_basic(usr_promt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1747720-a40b-4cf8-ad98-9addc8e9c339",
   "metadata": {},
   "source": [
    "# 会話コンテキストの維持"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e50d5c-86f1-447f-b2f2-064ff7b1665b",
   "metadata": {},
   "source": [
    "言語モデルとの会話では、異なるロール間でメッセージが交換されます。「assistant」ロールは、ユーザー入力に対するモデルの応答を表します。メッセージ履歴に{\"role\": \"assistant\", \"content\": assistant_msg}を追加するとき、モデルの最後の返答を保存しています。これにより、複数ターンの会話でコンテキストを維持し、モデルが以前に言ったことを記憶して、それに応じて応答できるようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac664bef-21b0-4ffe-b427-82284ea751e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_4_conversation(messages):   \n",
    "    response = requests.post(\"http://localhost:11434/api/chat\", json={\n",
    "        \"model\": \"llama3.1:8b\",\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    })\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        assistant_msg = response.json()[\"message\"][\"content\"]\n",
    "        return assistant_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f73add-49da-4c21-b0fd-c6077cc2b11e",
   "metadata": {},
   "source": [
    "### 会話を開始："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b177fcb2-bb92-4634-9da1-ff968bc39b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n例4: 会話\")\n",
    "print(\"-\" * 30)\n",
    "messages = [{\"role\": \"system\", \"content\": \"あなたは役立つコーディングアシスタントです。\"}]\n",
    "messages.append({\"role\": \"user\", \"content\": \"Pythonでファイルを読み込むにはどうすればいいですか？\"})\n",
    "assistant_msg = example_4_conversation(messages)\n",
    "print(f\"アシスタント:\\n{assistant_msg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf5c67c-e965-4ff6-9494-aa74952e67ae",
   "metadata": {},
   "source": [
    "### アシスタントを追加："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad8f2e8-40cd-4808-9535-4eac01c4ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\"role\": \"assistant\", \"content\": assistant_msg})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d21e9ae-56bf-476d-bc60-f438f089ad73",
   "metadata": {},
   "source": [
    "### フォローアップの質問を追加："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f404cd71-1b4f-4ce4-8fdd-4e770df77817",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"エラー処理についてはどうですか？\"})\n",
    "answer = example_4_conversation(messages)\n",
    "print(f\"\\n\\nフォローアップ:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bda394-a2b4-4e9e-a67b-18b0c30d8750",
   "metadata": {},
   "source": [
    "✅ すべての例が完了しました！\n",
    "\n",
    "💡 重要なポイント：\n",
    "\n",
    "• OpenAIのURLをhttp://localhost:11434に置き換える\n",
    "\n",
    "• APIキーは不要！\n",
    "\n",
    "• LangChainでChatOpenAIをChatOllamaに置き換える"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
